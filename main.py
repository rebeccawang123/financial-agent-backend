import os
import json
import base64 # ç”¨äº PPT å›¾ç‰‡ç¼–ç 
from typing import TypedDict, List, Dict, Any
from dotenv import load_dotenv

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI # ç”¨äº TTS è¯­éŸ³åˆæˆ
from pptx import Presentation # ç”¨äº PPT ç”Ÿæˆ
from pptx.util import Inches # PPT å°ºå¯¸

load_dotenv()

# --- 0. åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (ç”¨äº TTS) ---
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- 1. å®šä¹‰çŠ¶æ€ (State) ---
class AgentState(TypedDict):
    query: str
    news_data: List[str]
    sources: List[Dict[str, str]]
    podcast_insights: str
    logs: List[str]
    final_report: str
    report_chinese: str # æ–°å¢: ä¸­æ–‡æŠ¥å‘Š
    report_english: str # æ–°å¢: è‹±æ–‡æŠ¥å‘Š
    audio_chinese_b64: str # æ–°å¢: ä¸­æ–‡è¯­éŸ³ (Base64 ç¼–ç )
    audio_english_b64: str # æ–°å¢: è‹±æ–‡è¯­éŸ³ (Base64 ç¼–ç )
    ppt_b64: str # æ–°å¢: PPT æ–‡ä»¶ (Base64 ç¼–ç )

# --- 2. åˆå§‹åŒ– ---
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
search_tool = TavilySearchResults(max_results=3)

# --- 3. å®šä¹‰èŠ‚ç‚¹ (Nodes) ---

def news_node(state: AgentState):
    """æ–°é—»æœé›†å‘˜"""
    query = state.get("query", "Macro Finance")
    logs = state.get("logs", [])
    logs.append(f"ğŸ•µï¸ [News Agent] å¼€å§‹æœç´¢: '{query}'...")
    
    try:
        results = search_tool.invoke(f"{query} financial news bloomberg wsj")
        news_content = [res['content'] for res in results]
        sources = [{"title": res['content'][:30]+"...", "url": res['url']} for res in results]
        logs.append(f"âœ… [News Agent] æˆåŠŸæŠ“å–åˆ° {len(results)} æ¡ç›¸å…³æ–°é—»ã€‚")
    except Exception as e:
        print(f"Search failed: {e}")
        logs.append("âš ï¸ [News Agent] æœç´¢ API æœªå“åº”ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æµã€‚")
        news_content = [
            "Fed minutes suggest pause in rate cuts for December.",
            "NVIDIA stock volatility increases ahead of earnings.",
            "Bitcoin breaks $98k resistance level on ETF inflows."
        ]
        sources = [
            {"title": "WSJ: Fed Minutes Analysis", "url": "https://www.wsj.com/economy/central-banking"},
            {"title": "Bloomberg: Crypto Market Update", "url": "https://www.bloomberg.com/crypto"},
            {"title": "Reuters: Tech Stocks Rally", "url": "https://www.reuters.com/markets/us"}
        ]
        
    return {"news_data": news_content, "sources": sources, "logs": logs}

def podcast_node(state: AgentState):
    """æ’­å®¢ç›‘å¬å‘˜"""
    logs = state.get("logs", [])
    logs.append("ğŸ§ [Pod Listener] æ­£åœ¨æ¥å…¥ RSS æº: 'All-In Podcast'...")
    logs.append("ğŸ“ [Pod Listener] éŸ³é¢‘è½¬å½•å®Œæˆï¼Œæ­£åœ¨æå–å…³é”®è§‚ç‚¹...")
    
    mock_insight = """
    Chamath: AI infrastructure capex is peaking.
    Sacks: US Debt ceiling will be the main topic in 2025.
    """
    logs.append("âœ… [Pod Listener] è§‚ç‚¹æå–å®Œæ¯•ã€‚")
    return {"podcast_insights": mock_insight, "logs": logs}

def analyst_node(state: AgentState):
    """é¦–å¸­åˆ†æå¸ˆ - ç”Ÿæˆä¸­è‹±æ–‡æŠ¥å‘Š"""
    logs = state.get("logs", [])
    logs.append("ğŸ§  [Chief Analyst] æ­£åœ¨äº¤å‰éªŒè¯æ•°æ®ï¼Œå‡†å¤‡ç”Ÿæˆå¤šè¯­è¨€ Markdown æŠ¥å‘Š...")
    
    news = "\n".join(state['news_data'])
    podcast = state['podcast_insights']
    
    # ç”Ÿæˆè‹±æ–‡æŠ¥å‘Š
    prompt_en = ChatPromptTemplate.from_template("""
    You are a Wall Street Chief Analyst. Based on news: {news} and podcast insights: {podcast}.
    Write a "Daily Financial Briefing" including: Market Sentiment, Macro Analysis, Web3 Watch, and Actionable Insights.
    Use Markdown format, and include Emojis.
    """)
    chain_en = prompt_en | llm
    response_en = chain_en.invoke({"news": news, "podcast": podcast})
    
    # ç”Ÿæˆä¸­æ–‡æŠ¥å‘Š
    prompt_zh = ChatPromptTemplate.from_template("""
    ä½ æ˜¯åå°”è¡—é¦–å¸­åˆ†æå¸ˆã€‚åŸºäºæ–°é—»: {news} å’Œæ’­å®¢: {podcast}ã€‚
    å†™ä¸€ä»½ã€æ¯æ—¥é‡‘èæ™¨æŠ¥ã€‘ï¼ŒåŒ…å«ï¼šå¸‚åœºæƒ…ç»ªã€å®è§‚åˆ†æã€Web3è§‚å¯Ÿã€æ“ä½œå»ºè®®ã€‚
    ä½¿ç”¨ Markdown æ ¼å¼ï¼Œå¤šç”¨ Emojiã€‚
    """)
    chain_zh = prompt_zh | llm
    response_zh = chain_zh.invoke({"news": news, "podcast": podcast})
    
    logs.append("ğŸš€ [System] ä¸­è‹±æ–‡æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚")
    return {
        "report_english": response_en.content,
        "report_chinese": response_zh.content,
        "logs": logs
    }

def speech_node(state: AgentState):
    """è¯­éŸ³åˆæˆå‘˜"""
    logs = state.get("logs", [])
    logs.append("ğŸ—£ï¸ [Speech Synthesizer] æ­£åœ¨å°†æŠ¥å‘Šè½¬æ¢ä¸ºä¸­è‹±æ–‡è¯­éŸ³...")
    
    report_zh = state['report_chinese']
    report_en = state['report_english']

    # å°è¯•ä¸­æ–‡è¯­éŸ³åˆæˆ
    try:
        speech_zh_response = openai_client.audio.speech.create(
            model="tts-1",
            voice="alloy", # æˆ– "nova", "shimmer" ç­‰
            input=report_zh[:4096] # TTS API é™åˆ¶è¾“å…¥é•¿åº¦ï¼Œåªå–å‰4096å­—ç¬¦
        )
        audio_zh_bytes = speech_zh_response.read()
        audio_chinese_b64 = base64.b64encode(audio_zh_bytes).decode('utf-8')
        logs.append("âœ… [Speech Synthesizer] ä¸­æ–‡è¯­éŸ³ç”ŸæˆæˆåŠŸã€‚")
    except Exception as e:
        logs.append(f"âŒ [Speech Synthesizer] ä¸­æ–‡è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        audio_chinese_b64 = ""

    # å°è¯•è‹±æ–‡è¯­éŸ³åˆæˆ
    try:
        speech_en_response = openai_client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=report_en[:4096]
        )
        audio_en_bytes = speech_en_response.read()
        audio_english_b64 = base64.b64encode(audio_en_bytes).decode('utf-8')
        logs.append("âœ… [Speech Synthesizer] è‹±æ–‡è¯­éŸ³ç”ŸæˆæˆåŠŸã€‚")
    except Exception as e:
        logs.append(f"âŒ [Speech Synthesizer] è‹±æ–‡è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
        audio_english_b64 = ""

    return {
        "audio_chinese_b64": audio_chinese_b64,
        "audio_english_b64": audio_english_b64,
        "logs": logs
    }

def ppt_node(state: AgentState):
    """PPT ç”Ÿæˆå™¨"""
    logs = state.get("logs", [])
    logs.append("ğŸ“Š [PPT Generator] æ­£åœ¨æ•´ç†æŠ¥å‘Šå†…å®¹ï¼Œå‡†å¤‡ç”Ÿæˆæ¼”ç¤ºæ–‡ç¨¿...")
    
    report_title = "æ¯æ—¥é‡‘èæ™¨æŠ¥"
    report_content = state['report_chinese'] # ä½¿ç”¨ä¸­æ–‡æŠ¥å‘Šç”Ÿæˆ PPT
    
    prs = Presentation()
    
    # ç¬¬ä¸€é¡µï¼šæ ‡é¢˜é¡µ
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = report_title
    subtitle.text = f"ç”± AlphaBrief.ai ç”Ÿæˆ\n{json.dumps(state['sources'], indent=2, ensure_ascii=False)[:200]}..." # ç®€å•å±•ç¤ºæ¥æº

    # ç¬¬äºŒé¡µï¼šå†…å®¹é¡µ
    bullet_slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(bullet_slide_layout)
    title = slide.shapes.title
    body = slide.shapes.placeholders[1]
    
    title.text = "æ ¸å¿ƒæ´å¯Ÿ (Key Insights)"
    
    # ç®€å•åœ°æŠŠ Markdown æŠ¥å‘Šæ‹†åˆ†æˆæ®µè½
    content_parts = [part.strip() for part in report_content.split('\n\n') if part.strip()]
    
    tf = body.text_frame
    tf.clear()
    for part in content_parts:
        p = tf.add_paragraph()
        p.text = part # ç›´æ¥å°†æŠ¥å‘Šå†…å®¹ä½œä¸ºæ®µè½æ·»åŠ 
        # æ›´å¤š PPT æ ·å¼éœ€è¦æ›´å¤æ‚çš„è§£æ
        
    # ä¿å­˜ PPT åˆ°å†…å­˜
    from io import BytesIO
    ppt_stream = BytesIO()
    prs.save(ppt_stream)
    ppt_stream.seek(0) # å°†æŒ‡é’ˆç§»åˆ°å¼€å¤´
    
    ppt_b64 = base64.b64encode(ppt_stream.read()).decode('utf-8')
    
    logs.append("âœ… [PPT Generator] PPT æ–‡æ¡£ç”ŸæˆæˆåŠŸã€‚")
    return {"ppt_b64": ppt_b64, "logs": logs}

# --- 4. æ„å»ºå›¾ ---
workflow = StateGraph(AgentState)
workflow.add_node("news_scout", news_node)
workflow.add_node("podcast_listener", podcast_node)
workflow.add_node("chief_analyst", analyst_node) # æ–°å¢åˆ†æå¸ˆèŠ‚ç‚¹
workflow.add_node("speech_synthesizer", speech_node) # æ–°å¢è¯­éŸ³èŠ‚ç‚¹
workflow.add_node("ppt_generator", ppt_node) # æ–°å¢ PPT èŠ‚ç‚¹

workflow.set_entry_point("news_scout")
workflow.add_edge("news_scout", "podcast_listener")
workflow.add_edge("podcast_listener", "chief_analyst")
workflow.add_edge("chief_analyst", "speech_synthesizer")
workflow.add_edge("speech_synthesizer", "ppt_generator") # è¯­éŸ³åç”Ÿæˆ PPT
workflow.add_edge("ppt_generator", END)

app_graph = workflow.compile()

# --- 5. API ---
app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class ReportRequest(BaseModel):
    topic: str = "ä»Šæ—¥å¸‚åœº"

@app.post("/generate_report")
async def generate_report(req: ReportRequest):
    inputs = {"query": req.topic, "logs": []}
    result = await app_graph.ainvoke(inputs)
    return {
        "report_chinese": result["report_chinese"],
        "report_english": result["report_english"],
        "sources": result["sources"],
        "logs": result["logs"],
        "audio_chinese_b64": result["audio_chinese_b64"],
        "audio_english_b64": result["audio_english_b64"],
        "ppt_b64": result["ppt_b64"]
    }

# æ–°å¢ä¸€ä¸ªä¸‹è½½ PPT çš„è·¯ç”±
@app.get("/download_ppt")
async def download_ppt(ppt_b64: str):
    ppt_bytes = base64.b64decode(ppt_b64)
    return Response(content=ppt_bytes, media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                    headers={"Content-Disposition": "attachment; filename=Financial_Briefing.pptx"})