import os
import json
import base64
import asyncio # å¼•å…¥ asyncio
from typing import TypedDict, List, Dict, Any
from dotenv import load_dotenv

from langgraph.graph import StateGraph, END
# åˆ‡æ¢ä¸º Google Gemini
from langchain_google_genai import ChatGoogleGenerativeAI 
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.tools.tavily_search import TavilySearchResults
from fastapi import FastAPI, Response
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pptx import Presentation
import edge_tts # å¼•å…¥ Edge TTS

load_dotenv()

# --- 1. å®šä¹‰çŠ¶æ€ ---
class AgentState(TypedDict):
    query: str
    news_data: List[str]
    sources: List[Dict[str, str]]
    podcast_insights: str
    logs: List[str]
    final_report: str
    report_chinese: str
    report_english: str
    audio_chinese_b64: str
    audio_english_b64: str
    ppt_b64: str

# --- 2. åˆå§‹åŒ– ---
# ä½¿ç”¨ Gemini 1.5 Flash (å…è´¹ä¸”å¿«)
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    temperature=0,
    google_api_key=os.getenv("GOOGLE_API_KEY")
)
search_tool = TavilySearchResults(max_results=3)

# --- 3. å®šä¹‰èŠ‚ç‚¹ ---

def news_node(state: AgentState):
    """æ–°é—»æœé›†å‘˜"""
    query = state.get("query", "Macro Finance")
    logs = state.get("logs", [])
    logs.append(f"ğŸ•µï¸ [News Agent] æ­£åœ¨ä½¿ç”¨ Gemini Flash æœç´¢: '{query}'...")
    
    try:
        results = search_tool.invoke(f"{query} financial news bloomberg wsj")
        news_content = [res['content'] for res in results]
        sources = [{"title": res['content'][:30]+"...", "url": res['url']} for res in results]
        logs.append(f"âœ… [News Agent] æˆåŠŸæŠ“å–åˆ° {len(results)} æ¡ç›¸å…³æ–°é—»ã€‚")
    except Exception as e:
        logs.append("âš ï¸ [News Agent] æœç´¢ API æœªå“åº”ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æµã€‚")
        news_content = ["Market data unavailable due to network."]
        sources = []
        
    return {"news_data": news_content, "sources": sources, "logs": logs}

def podcast_node(state: AgentState):
    """æ’­å®¢ç›‘å¬å‘˜"""
    logs = state.get("logs", [])
    logs.append("ğŸ§ [Pod Listener] æ­£åœ¨æ¥å…¥ RSS æº: 'All-In Podcast'...")
    mock_insight = "Chamath: AI infrastructure capex is peaking. Sacks: US Debt ceiling will be the main topic in 2025."
    return {"podcast_insights": mock_insight, "logs": logs}

def analyst_node(state: AgentState):
    """é¦–å¸­åˆ†æå¸ˆ"""
    logs = state.get("logs", [])
    logs.append("ğŸ§  [Chief Analyst] Gemini 1.5 Flash æ­£åœ¨ç”ŸæˆåŒè¯­ç ”æŠ¥...")
    
    news = "\n".join(state['news_data'])
    podcast = state['podcast_insights']
    
    # è‹±æ–‡æç¤ºè¯
    prompt_en = ChatPromptTemplate.from_template("""
    You are a Wall Street Analyst. Based on: {news} and {podcast}.
    Write a brief "Daily Financial Briefing". Use Markdown.
    """)
    chain_en = prompt_en | llm
    response_en = chain_en.invoke({"news": news, "podcast": podcast})
    
    # ä¸­æ–‡æç¤ºè¯
    prompt_zh = ChatPromptTemplate.from_template("""
    ä½ æ˜¯åå°”è¡—åˆ†æå¸ˆã€‚åŸºäº: {news} å’Œ {podcast}ã€‚
    å†™ä¸€ä»½ç®€çŸ­çš„ã€æ¯æ—¥é‡‘èæ™¨æŠ¥ã€‘ã€‚ä½¿ç”¨ Markdown æ ¼å¼ï¼ŒåŒ…å« Emojiã€‚
    """)
    chain_zh = prompt_zh | llm
    response_zh = chain_zh.invoke({"news": news, "podcast": podcast})
    
    logs.append("ğŸš€ [System] æŠ¥å‘Šç”Ÿæˆå®Œæ¯•ã€‚")
    return {
        "report_english": response_en.content,
        "report_chinese": response_zh.content,
        "logs": logs
    }

# --- âš ï¸ æ ¸å¿ƒä¿®æ”¹: ä½¿ç”¨ Edge TTS (å¼‚æ­¥) ---
async def speech_node(state: AgentState):
    """è¯­éŸ³åˆæˆå‘˜ (Edge TTS ç‰ˆ)"""
    logs = state.get("logs", [])
    logs.append("ğŸ—£ï¸ [Edge TTS] æ­£åœ¨è°ƒç”¨å¾®è½¯ Neural è¯­éŸ³å¼•æ“...")
    
    report_zh = state['report_chinese']
    report_en = state['report_english']
    
    audio_chinese_b64 = ""
    audio_english_b64 = ""

    # 1. ç”Ÿæˆä¸­æ–‡è¯­éŸ³ (æ¨è: zh-CN-YunxiNeural - ç”·å£°æ–°é—»è…”)
    try:
        communicate = edge_tts.Communicate(report_zh[:50], "zh-CN-YunxiNeural")
        # å°†éŸ³é¢‘æµå†™å…¥å†…å­˜
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        audio_chinese_b64 = base64.b64encode(audio_data).decode('utf-8')
        logs.append("âœ… [Edge TTS] ä¸­æ–‡è¯­éŸ³ç”ŸæˆæˆåŠŸ (Free)ã€‚")
    except Exception as e:
        logs.append(f"âŒ [Edge TTS] ä¸­æ–‡ç”Ÿæˆå¤±è´¥: {str(e)}")

    # 2. ç”Ÿæˆè‹±æ–‡è¯­éŸ³ (æ¨è: en-US-ChristopherNeural - ç”·å£°ä¸“ä¸šè…”)
    try:
        communicate = edge_tts.Communicate(report_en[:50], "en-US-ChristopherNeural")
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        audio_english_b64 = base64.b64encode(audio_data).decode('utf-8')
        logs.append("âœ… [Edge TTS] è‹±æ–‡è¯­éŸ³ç”ŸæˆæˆåŠŸ (Free)ã€‚")
    except Exception as e:
        logs.append(f"âŒ [Edge TTS] è‹±æ–‡ç”Ÿæˆå¤±è´¥: {str(e)}")

    return {
        "audio_chinese_b64": audio_chinese_b64,
        "audio_english_b64": audio_english_b64,
        "logs": logs
    }

def ppt_node(state: AgentState):
    """PPT ç”Ÿæˆå™¨"""
    logs = state.get("logs", [])
    logs.append("ğŸ“Š [PPT Generator] æ­£åœ¨ç”Ÿæˆæ¼”ç¤ºæ–‡ç¨¿...")
    
    prs = Presentation()
    slide = prs.slides.add_slide(prs.slide_layouts[0])
    slide.shapes.title.text = "æ¯æ—¥é‡‘èæ™¨æŠ¥"
    slide.placeholders[1].text = "Powered by AlphaBrief.ai"
    
    # ç®€å•å†…å®¹é¡µ
    slide2 = prs.slides.add_slide(prs.slide_layouts[1])
    slide2.shapes.title.text = "æ ¸å¿ƒæ‘˜è¦"
    slide2.shapes.placeholders[1].text = state['report_chinese'][:500]
    
    from io import BytesIO
    ppt_stream = BytesIO()
    prs.save(ppt_stream)
    ppt_stream.seek(0)
    ppt_b64 = base64.b64encode(ppt_stream.read()).decode('utf-8')
    
    logs.append("âœ… [PPT] æ–‡æ¡£æ‰“åŒ…å®Œæˆã€‚")
    return {"ppt_b64": ppt_b64, "logs": logs}

# --- 4. æ„å»ºå›¾ ---
workflow = StateGraph(AgentState)
workflow.add_node("news_scout", news_node)
workflow.add_node("podcast_listener", podcast_node)
workflow.add_node("chief_analyst", analyst_node)
workflow.add_node("speech_synthesizer", speech_node)
workflow.add_node("ppt_generator", ppt_node)

workflow.set_entry_point("news_scout")
workflow.add_edge("news_scout", "podcast_listener")
workflow.add_edge("podcast_listener", "chief_analyst")
workflow.add_edge("chief_analyst", "speech_synthesizer")
workflow.add_edge("speech_synthesizer", "ppt_generator")
workflow.add_edge("ppt_generator", END)

app_graph = workflow.compile()

# --- 5. API ---
app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class ReportRequest(BaseModel):
    topic: str = "ä»Šæ—¥å¸‚åœº"

@app.post("/generate_report")
async def generate_report(req: ReportRequest):
    inputs = {"query": req.topic, "logs": []}
    result = await app_graph.ainvoke(inputs)
    return {
        "report_chinese": result["report_chinese"],
        "report_english": result["report_english"],
        "sources": result["sources"],
        "logs": result["logs"],
        "audio_chinese_b64": result["audio_chinese_b64"],
        "audio_english_b64": result["audio_english_b64"],
        "ppt_b64": result["ppt_b64"]
    }